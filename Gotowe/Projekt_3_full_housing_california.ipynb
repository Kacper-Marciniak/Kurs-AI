{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "DATASET_PATH = \"Dane\\\\CaliforniaHousing.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie datasetu California Housing\n",
    "dataset = pd.read_csv(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informacje o zestawie danych\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brakujące dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Znalezienie brakujących danych\n",
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W rzędzie jest brakująca wartość\n",
    "isnull = dataset.isnull().any(axis=1)\n",
    "print(np.count_nonzero(isnull),\"brakujących wartości.\")\n",
    "# Usunięcie rzędu\n",
    "dataset = dataset.drop(np.asarray(isnull).nonzero()[0].tolist() ,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podgląd pierwszych 10 rzędów\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Znalezienie kolumn z danymi kategorialnymi (nienumerycznymi)\n",
    "dataset_cat=dataset.select_dtypes(include='object')\n",
    "dataset_cat.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wydzielenie zmiennej zależnej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wydzielenie zmiennej zależnej (Y)\n",
    "dataset[\"median_house_value\"] /= 1000\n",
    "x,y = dataset.drop(columns=[\"median_house_value\"]), dataset[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podstawowa analiza statystyczna\n",
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hisotgramy zmiennych niezależnych\n",
    "x.hist(figsize=(15,10), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analiza korelacji pomiędzy zmiennymi\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "sns.heatmap(x.select_dtypes(exclude='object').corr(), ax=ax, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test, Val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podział na subsety TRAIN, TEST oraz VAL\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.4, random_state=5, shuffle=True)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skalowanie wartości niezależnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skalowanie zmiennych niezależnych numerycznych z użyciem StandardScaler\n",
    "# Enkodowanie zmiennych niezależnych kategorycznych z użyciem OrdinalEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder \n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "\n",
    "col_categorical = x_train.select_dtypes(include='object').columns\n",
    "col_numerical = x_train.select_dtypes(exclude='object').columns\n",
    "\n",
    "col_transformer = make_column_transformer(\n",
    "    (StandardScaler(), col_numerical),\n",
    "    (OrdinalEncoder(), col_categorical)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresja - model regresji linowej, drzewo decyzyjne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresja liniowa\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regressor = Pipeline([\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('linear_regressor', LinearRegression(positive=True))\n",
    "])\n",
    "linear_regressor.fit(x_train, y_train)\n",
    "\n",
    "y_pred = linear_regressor.predict(x_train)\n",
    "print(f\"RMSE: {mean_squared_error(y_train, y_pred)**.5:.2f}\")\n",
    "print(f\"R^2: {r2_score(y_train, y_pred):.3f}\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "ax.plot(y_train, y_pred, '.')\n",
    "ax.plot([0, np.max(y_val)], [0, np.max(y_val)], color='red', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel(\"Oczekiwane wartości\")\n",
    "ax.set_ylabel(\"Predykcje\")\n",
    "ax.set_title(\"Zestaw treningowy\")\n",
    "ax.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drzewo decyzyjne\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "decision_tree = Pipeline([\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('decision_tree', DecisionTreeRegressor())\n",
    "])\n",
    "decision_tree.fit(x_train, y_train)\n",
    "\n",
    "y_pred = decision_tree.predict(x_train)\n",
    "print(f\"RMSE: {mean_squared_error(y_train, y_pred)**.5:.2f}\")\n",
    "print(f\"R^2: {r2_score(y_train, y_pred):.3f}\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "ax.plot(y_train, y_pred, '.')\n",
    "ax.plot([0, np.max(y_val)], [0, np.max(y_val)], color='red', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel(\"Oczekiwane wartości\")\n",
    "ax.set_ylabel(\"Predykcje\")\n",
    "ax.set_title(\"Zestaw treningowy\")\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ewaluacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ewaluacja regresji liniowej na zestawie walidacyjnym\n",
    "\n",
    "y_pred = linear_regressor.predict(x_val)\n",
    "print(f\"RMSE: {mean_squared_error(y_val, y_pred)**.5:.2f}\")\n",
    "print(f\"R^2: {r2_score(y_val, y_pred):.3f}\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "ax.plot(y_val, y_pred, '.')\n",
    "ax.plot([0, np.max(y_val)], [0, np.max(y_val)], color='red', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel(\"Oczekiwane wartości\")\n",
    "ax.set_ylabel(\"Predykcje\")\n",
    "ax.set_title(\"Zestaw walidacyjny\")\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ewaluacja drzewa decyzyjnego na zestawie walidacyjnym\n",
    "\n",
    "y_pred = decision_tree.predict(x_val)\n",
    "print(f\"RMSE: {mean_squared_error(y_val, y_pred)**.5:.2f}\")\n",
    "print(f\"R^2: {r2_score(y_val, y_pred):.3f}\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "ax.plot(y_val, y_pred, '.')\n",
    "ax.plot([0, np.max(y_val)], [0, np.max(y_val)], color='red', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel(\"Oczekiwane wartości\")\n",
    "ax.set_ylabel(\"Predykcje\")\n",
    "ax.set_title(\"Zestaw walidacyjny\")\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strojenie hiperparametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listowanie parametrów drzewa decyzyjnego\n",
    "decision_tree['decision_tree'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning hiperparametrów drzewa decyzyjnego z wykorzystaniem GridSearchCV \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'decision_tree__max_depth': [5, 10, 15, 20, 25],\n",
    "    'decision_tree__min_samples_split': [2, 5, 10, 15, 20],\n",
    "    'decision_tree__min_samples_leaf': [1, 2, 5, 10, 15]\n",
    "}\n",
    "grid_search = GridSearchCV(decision_tree, parameters)\n",
    "grid_search.fit(x_val, y_val)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zastosowanie hiperparametrów i ponowny trening\n",
    "for param, val in grid_search.best_params_.items():\n",
    "    decision_tree.set_params(**{param: val})\n",
    "\n",
    "decision_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ewaluacja na zestawie walidacyjnym\n",
    "y_pred = decision_tree.predict(x_val)\n",
    "print(f\"RMSE: {mean_squared_error(y_val, y_pred)**.5:.2f}\")\n",
    "print(f\"R^2: {r2_score(y_val, y_pred):.3f}\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "ax.plot(y_val, y_pred, '.')\n",
    "ax.plot([0, np.max(y_val)], [0, np.max(y_val)], color='red', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel(\"Oczekiwane wartości\")\n",
    "ax.set_ylabel(\"Predykcje\")\n",
    "ax.set_title(\"Zestaw walidacyjny\")\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selekcja cech metodą LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresja Lasso do oceny ważności zmiennych niezależnych\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Pipeline([\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('lasso', Lasso(alpha=1e-05, max_iter=4000))\n",
    "])\n",
    "\n",
    "lasso.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyznaczenie ważności zmiennych niezależnych i ich wizualizacja\n",
    "\n",
    "lasso_coef = np.abs(lasso['lasso'].coef_)\n",
    "lasso_coef /= np.sum(lasso_coef)\n",
    "\n",
    "THRESH = 0.05\n",
    "\n",
    "decision_tree_coef = np.abs(decision_tree['decision_tree'].feature_importances_)\n",
    "decision_tree_coef /= np.sum(decision_tree_coef)\n",
    "\n",
    "# plotting the Column Names and Importance of Columns. \n",
    "fig,axes = plt.subplots(1,2,figsize=(10,3))\n",
    "\n",
    "axes[0].bar(x_train.columns.values, lasso_coef)\n",
    "axes[0].axhline(y=THRESH, color='r', linestyle='-')\n",
    "axes[0].grid()\n",
    "axes[0].set_xticks(x_train.columns.values)\n",
    "axes[0].set_xticklabels(x_train.columns.values, rotation = 90)\n",
    "axes[0].set_title(\"Ważność cech wyznaczona metodą LASSO\")\n",
    "axes[0].set_xlabel(\"Nazwa cechy\")\n",
    "axes[0].set_ylabel(\"Wpływ\")\n",
    "\n",
    "axes[1].bar(x_train.columns.values, decision_tree_coef)\n",
    "axes[1].grid()\n",
    "axes[1].set_xticks(x_train.columns.values)\n",
    "axes[1].set_xticklabels(x_train.columns.values, rotation = 90)\n",
    "axes[1].set_title(\"Wpływ cech na model - Decision Tree\")\n",
    "axes[1].set_xlabel(\"Nazwa cechy\")\n",
    "axes[1].set_ylabel(\"Wpływ\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "features_selected = x_train.columns[lasso_coef > THRESH]\n",
    "features_ignored = x_train.columns[lasso_coef <= THRESH]\n",
    "print(features_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usunięcie zmiennych nieistotnych\n",
    "x_train = x_train.drop(columns=features_ignored)\n",
    "x_val = x_val.drop(columns=features_ignored)\n",
    "x_test = x_test.drop(columns=features_ignored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ponowne stworzenie pipeline'u oraz trenowanie modelu drzewa decyzyjnego dla zestawu z nowymi zmiennymi\n",
    "\n",
    "col_categorical = x_train.select_dtypes(include='object').columns\n",
    "col_numerical = x_train.select_dtypes(exclude='object').columns\n",
    "\n",
    "col_transformer = make_column_transformer(\n",
    "    (StandardScaler(), col_numerical),\n",
    "    (OrdinalEncoder(), col_categorical)\n",
    ")\n",
    "\n",
    "decision_tree = Pipeline([\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('decision_tree', DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'decision_tree__max_depth': [5, 10, 15, 20, 25],\n",
    "    'decision_tree__min_samples_split': [2, 5, 10, 15, 20],\n",
    "    'decision_tree__min_samples_leaf': [1, 2, 5, 10, 15]\n",
    "}\n",
    "grid_search = GridSearchCV(decision_tree, parameters)\n",
    "grid_search.fit(x_val, y_val)\n",
    "\n",
    "grid_search.best_params_\n",
    "\n",
    "for param, val in grid_search.best_params_.items():\n",
    "    decision_tree.set_params(**{param: val})\n",
    "\n",
    "decision_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyznaczenie wpłwu cech niezależnych na model\n",
    "\n",
    "decision_tree_coef = np.abs(decision_tree['decision_tree'].feature_importances_)\n",
    "decision_tree_coef /= np.sum(decision_tree_coef)\n",
    "\n",
    "# plotting the Column Names and Importance of Columns. \n",
    "fig,ax = plt.subplots(1,1,figsize=(5,3))\n",
    "\n",
    "ax.bar(x_train.columns.values, decision_tree_coef)\n",
    "ax.grid()\n",
    "ax.set_xticks(x_train.columns.values)\n",
    "ax.set_xticklabels(x_train.columns.values, rotation = 90)\n",
    "ax.set_title(\"Wpływ cech na model - Decision Tree\")\n",
    "ax.set_xlabel(\"Nazwa cechy\")\n",
    "ax.set_ylabel(\"Wpływ\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ewaluacja na zestawie walidacyjnym\n",
    "y_pred = decision_tree.predict(x_val)\n",
    "print(f\"RMSE: {mean_squared_error(y_val, y_pred)**.5:.2f}\")\n",
    "print(f\"R^2: {r2_score(y_val, y_pred):.3f}\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "ax.plot(y_val, y_pred, '.')\n",
    "ax.plot([0, np.max(y_val)], [0, np.max(y_val)], color='red', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel(\"Oczekiwane wartości\")\n",
    "ax.set_ylabel(\"Predykcje\")\n",
    "ax.set_title(\"Zestaw walidacyjny\")\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walidacja na zbiorze testowym (finalna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decision_tree.predict(x_test)\n",
    "print(f\"RMSE: {mean_squared_error(y_test, y_pred)**.5:.2f}\")\n",
    "print(f\"R^2: {r2_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "ax.plot(y_test, y_pred, '.')\n",
    "ax.plot([0, np.max(y_val)], [0, np.max(y_val)], color='red', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel(\"Oczekiwane wartości\")\n",
    "ax.set_ylabel(\"Predykcje\")\n",
    "ax.set_title(\"Zestaw testowy\") \n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
