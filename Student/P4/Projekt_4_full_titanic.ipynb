{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wprowadzenie - klasyfikacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "x, y = make_blobs(n_samples=300, n_features=2, random_state=12, centers=3, shuffle=True, cluster_std=1.5)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=0, shuffle=True, stratify=y)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "svml = SVC(kernel='linear', C=1.0, random_state=0)\n",
    "svmrbf = SVC(kernel='rbf', C=1.0, random_state=0)\n",
    "\n",
    "for i, model in enumerate([knn, svml, svmrbf]): \n",
    "\n",
    "    # Train the model using the training sets\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # The mean squared error\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "\n",
    "    # Plot outputs\n",
    "    axes[i].scatter(x_test[:,0], x_test[:,1], c=y_test, marker='o')\n",
    "    axes[i].scatter(x_test[:,0], x_test[:,1], c=y_pred, marker='.')\n",
    "\n",
    "    axes[i].set_xticks(())\n",
    "    axes[i].set_yticks(())\n",
    "\n",
    "    axes[i].set_xlabel(\"Dimension 1\")\n",
    "    axes[0].set_ylabel(\"Dimension 2\")\n",
    "\n",
    "    axes[i].set_title(f\"Accuracy = {accuracy_score(y_test, y_pred):.2f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "DATASET_PATH = \"Titanic.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie datasetu Breast Cancer\n",
    "dataset = pd.read_csv(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informacje o zestawie danych\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FEATURE_LABELS = {\n",
    "    \"PassengerId\": \"Passenger ID\",\n",
    "    \"Survived\": \"Survival\",\n",
    "    \"Pclass\": \"Class\",\n",
    "    \"Name\": \"Name\",\n",
    "    \"Sex\": \"Sex\",\n",
    "    \"Age\": \"Age\",\n",
    "    \"SibSp\": \"Siblings/Spouses\",\n",
    "    \"Parch\": \"Parents/Children\",\n",
    "    \"Ticket\": \"Ticket Number\",\n",
    "    \"Fare\": \"Passenger Fare\",\n",
    "    \"Cabin\": \"Cabin\",\n",
    "    \"Embarked\": \"Port of embarkation\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zmiana nazwy kolumn\n",
    "dataset = dataset.rename(columns=DATASET_FEATURE_LABELS)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usunięcie zbędnych kolumn\n",
    "dataset = dataset.drop(columns=['Passenger ID', 'Name', 'Ticket Number', 'Cabin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brakujące dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Znalezienie brakujących danych\n",
    "dataset.isnull().any()\n",
    "# W rzędzie jest brakująca wartość\n",
    "isnull = dataset.isnull().any(axis=1)\n",
    "print(np.count_nonzero(isnull),\"brakujących wartości.\")\n",
    "# Usunięcie rzędu\n",
    "dataset = dataset.drop(np.asarray(isnull).nonzero()[0].tolist() ,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podgląd pierwszych 10 rzędów\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wydzielenie zmiennej zależnej, liczba klas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wydzielenie zmiennej zależnej (Y)\n",
    "x,y = dataset.drop(columns=[\"Survival\"]), dataset[\"Survival\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Określenie liczby klas\n",
    "counts = y.value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Współczynnik niezbalansowania\n",
    "c_max, c_min = max(counts.values[0],counts.values[1]),min(counts.values[0],counts.values[1])\n",
    "imbalance = c_max/c_min\n",
    "\n",
    "print(f\"Współczynnik niezbalansowania: {c_max} / {c_min} = {imbalance:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podstawowa analiza statystyczna\n",
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramy zmiennych niezależnych\n",
    "axes = x.hist(figsize=(10,8), bins=20, edgecolor='black', grid=False)\n",
    "# Dodatkowe formatowanie\n",
    "axes = axes.flatten()\n",
    "axes[0].set_xticks([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analiza BOXPLOT\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(12,4))\n",
    "sns.boxplot(x=y, y=x[\"Age\"], ax=axes[0])\n",
    "sns.boxplot(x=y, y=x[\"Age\"], hue=x[\"Class\"], ax=axes[1])\n",
    "sns.boxplot(x=x[\"Sex\"], y=x[\"Age\"], hue=y, ax=axes[2])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(12,4))\n",
    "sns.boxplot(x=y, y=x[\"Passenger Fare\"], ax=axes[0])\n",
    "sns.boxplot(x=y, y=x[\"Passenger Fare\"], hue=x[\"Class\"], ax=axes[1])\n",
    "sns.boxplot(x=x[\"Class\"], y=x[\"Passenger Fare\"], ax=axes[2])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analiza korelacji pomiędzy zmiennymi\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(x.select_dtypes(exclude='object').corr(), ax=ax, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modele klasyfikacji - SVM, kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder \n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "\n",
    "col_categorical = x.select_dtypes(include='object').columns\n",
    "col_numerical = x.select_dtypes(exclude='object').columns\n",
    "\n",
    "col_transformer = make_column_transformer(\n",
    "    (StandardScaler(), col_numerical),\n",
    "    (OrdinalEncoder(), col_categorical)\n",
    ")\n",
    "\n",
    "from  sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Enkodowanie zmiennej zależnej\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "y_name_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "svc = Pipeline([\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('svc', SVC(kernel=\"linear\", C=1.0)),\n",
    "])\n",
    "\n",
    "knn = Pipeline([\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=3)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walidacja krzyżowa dla domyślnych hiperparametrów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jaki wpływ na model może mieć podział danych wejściowych na zestaw treningowy i walidacyjny?\n",
    "- Jak zachować się w przypadku małych zestawów danych?\n",
    "\n",
    "-> **Walidacja krzyżowa**:\n",
    "Zastosujemy walidację krzyżową aby porównać dwa modele - kNN oraz SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "SCORING = ('accuracy', 'recall', 'precision', 'f1')\n",
    "\n",
    "results = cross_validate(svc, x, y, cv=5, scoring=SCORING)\n",
    "\n",
    "print(\"=====\\nSVC:\\n=====\")\n",
    "for key in results.keys():\n",
    "    print(f\"{key}: {results[key].mean():.3f}\")\n",
    "\n",
    "results = cross_validate(knn, x, y, cv=5, scoring=SCORING)\n",
    "\n",
    "print(\"=====\\nk-NN:\\n=====\")\n",
    "for key in results.keys():\n",
    "    print(f\"{key}: {results[key].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dobór hiperparametrów metodą GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listowanie parametrów SVC\n",
    "svc['svc'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listowanie parametrów k-NN\n",
    "knn['knn'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning hiperparametrów k-NN z wykorzystaniem GridSearchCV \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'knn__n_neighbors': [1, 3, 5, 7, 9, 11],\n",
    "    'knn__metric': ['euclidean', 'cosine', 'cityblock', 'l1', 'l2', 'nan_euclidean'],\n",
    "}\n",
    "grid_search = GridSearchCV(knn, parameters)\n",
    "grid_search.fit(x, y)\n",
    "\n",
    "# Zastosowanie hiperparametrów\n",
    "for param, val in grid_search.best_params_.items():\n",
    "    knn.set_params(**{param: val})\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning hiperparametrów SVC z wykorzystaniem GridSearchCV \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'svc__C': list(np.arange(0.1, 2.1, 0.1)),\n",
    "    'svc__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "}\n",
    "grid_search = GridSearchCV(svc, parameters)\n",
    "grid_search.fit(x, y)\n",
    "\n",
    "# Zastosowanie hiperparametrów\n",
    "for param, val in grid_search.best_params_.items():\n",
    "    svc.set_params(**{param: val})\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_validate(svc, x, y, cv=5, scoring=SCORING)\n",
    "\n",
    "print(\"=====\\nSVC:\\n=====\")\n",
    "for key in results.keys():\n",
    "    print(f\"{key}: {results[key].mean():.3f}\")\n",
    "\n",
    "results = cross_validate(knn, x, y, cv=5, scoring=SCORING)\n",
    "\n",
    "print(\"=====\\nk-NN:\\n=====\")\n",
    "for key in results.keys():\n",
    "    print(f\"{key}: {results[key].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DODATEK: Porównanie klasyfikatorów\n",
    "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "#              Andreas Müller\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    SVC(gamma=2, C=1, random_state=42),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42),\n",
    "    DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
    "    ),\n",
    "    MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n",
    "    AdaBoostClassifier(algorithm=\"SAMME\", random_state=42),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1\n",
    ")\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [\n",
    "    make_moons(noise=0.3, random_state=0),\n",
    "    make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "    linearly_separable,\n",
    "]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.4, random_state=42\n",
    "    )\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "    # Plot the testing points\n",
    "    ax.scatter(\n",
    "        X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors=\"k\"\n",
    "    )\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "\n",
    "        clf = make_pipeline(StandardScaler(), clf)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        DecisionBoundaryDisplay.from_estimator(\n",
    "            clf, X, cmap=cm, alpha=0.8, ax=ax, eps=0.5\n",
    "        )\n",
    "\n",
    "        # Plot the training points\n",
    "        ax.scatter(\n",
    "            X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\"\n",
    "        )\n",
    "        # Plot the testing points\n",
    "        ax.scatter(\n",
    "            X_test[:, 0],\n",
    "            X_test[:, 1],\n",
    "            c=y_test,\n",
    "            cmap=cm_bright,\n",
    "            edgecolors=\"k\",\n",
    "            alpha=0.6,\n",
    "        )\n",
    "\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name)\n",
    "        ax.text(\n",
    "            x_max - 0.3,\n",
    "            y_min + 0.3,\n",
    "            (\"%.2f\" % score).lstrip(\"0\"),\n",
    "            size=15,\n",
    "            horizontalalignment=\"right\",\n",
    "        )\n",
    "        i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
