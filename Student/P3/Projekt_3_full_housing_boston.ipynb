{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wprowadzenie - regresja liniowa\n",
    "Oryginalny kod: https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 4))\n",
    "\n",
    "for i, noise in enumerate([1.0, 10.0, 25.0, 50.0]):\n",
    "    x, y, coef = make_regression(n_samples=100, n_features=1, noise=noise, random_state=0, coef=True)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=0, shuffle=True)\n",
    "    x = x.flatten()\n",
    "\n",
    "\n",
    "    # Create linear regression object\n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regr.fit(x_train, y_train)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = regr.predict(x_test)\n",
    "\n",
    "    # The mean squared error\n",
    "    print(f\"RMSE: {mean_squared_error(y_test, y_pred)**.5:.2f}\")\n",
    "\n",
    "    # Plot outputs\n",
    "    axes[i].scatter(x_test, y_test, color=\"black\")    \n",
    "    axes[i].plot([np.min(x_test),np.max(x_test)], [np.min(x_test)*coef,np.max(x_test)*coef], color=\"blue\", linewidth=1, alpha=1.0)\n",
    "    axes[i].plot(x_test, y_pred, color=\"red\", linewidth=3, alpha=0.55)\n",
    "\n",
    "    axes[i].set_xticks(())\n",
    "    axes[i].set_yticks(())\n",
    "\n",
    "    axes[i].set_xlabel(\"Dane wejściowe - X\\n(Zmienna niezależna)\")\n",
    "    axes[0].set_ylabel(\"Dane wyjściowe - Y\\n(Zmienna zależna)\")\n",
    "\n",
    "\n",
    "    axes[i].set_xlim(-2.5, 2.5)\n",
    "    axes[i].set_ylim(-150, 150)\n",
    "\n",
    "    axes[i].set_title(f\"Noise={int(noise)}, R^2={r2_score(y_test, y_pred):.2f}, RMSE={mean_squared_error(y_test, y_pred)**.5:.1f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATASET_PATH = \"Dane\\\\BostonHousing.csv\" # Ścieżka do pliku z danymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie datasetu California Housing\n",
    "dataset = pd.read_csv(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informacje o zestawie danych\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Własne etykiety i opisy dla cech\n",
    "DATASET_FEATURE_DSCRB = {\n",
    "    \"crim\": \"Per capita crime rate by town\",\n",
    "    \"zn\": \"Proportion of residential land zoned for lots over 25,000 sq.ft\",\n",
    "    \"indus\": \"Proportion of non-retail business acres per town\",\n",
    "    \"chas\": \"Charles River dummy variable (1 if tract bounds river; 0 otherwise)\",\n",
    "    \"nox\": \"Nitric oxides concentration (parts per 10 million)\",\n",
    "    \"RM\": \"Average number of rooms per dwelling\",\n",
    "    \"age\": \"Proportion of owner-occupied units built prior to 1940\",\n",
    "    \"dis\": \"Weighted distances to five Boston employment centres\",\n",
    "    \"rad\": \"Index of accessibility to radial highways\",\n",
    "    \"tax\": \"Full-value property-tax rate per $10,000\",\n",
    "    \"ptratio\": \"Pupil-teacher ratio by town\",\n",
    "    \"b\": \"1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\",\n",
    "    \"lstat\": \"[%] lower status of the population\",\n",
    "    \"medv\": \"Median value of owner-occupied homes in $1000's\",\n",
    "}\n",
    "DATASET_FEATURE_LABELS = {\n",
    "    \"crim\": \"crime\",\n",
    "    \"zn\": \"zoned prop.\",\n",
    "    \"indus\": \"industry prop.\",\n",
    "    \"chas\": \"Charles River\",\n",
    "    \"nox\": \"NOX\",\n",
    "    \"rm\": \"No. rooms\",\n",
    "    \"age\": \"pre-1940\",\n",
    "    \"dis\": \"weighted dist.\",\n",
    "    \"rad\": \"radial highways\",\n",
    "    \"tax\": \"property tax\",\n",
    "    \"ptratio\": \"pupil-teacher ratio\",\n",
    "    \"b\": \"proportion of blacks\",\n",
    "    \"lstat\": \"lower status\",\n",
    "    \"medv\": \"median value\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zmiana nazwy kolumn\n",
    "dataset = dataset.rename(columns=DATASET_FEATURE_LABELS)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brakujące dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Znalezienie brakujących danych\n",
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W rzędzie jest brakująca wartość\n",
    "isnull = dataset.isnull().any(axis=1)\n",
    "print(np.count_nonzero(isnull),\"brakujących wartości.\")\n",
    "# Usunięcie rzędu\n",
    "dataset = dataset.drop(np.asarray(isnull).nonzero()[0].tolist() ,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podgląd pierwszych 10 rzędów\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dane numeryczne**: 0, 1, -2, 1.37 ...\n",
    "\n",
    "**Dane kategorialne**: \"A\", \"samochód\", \"A23-1b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Znalezienie kolumn z danymi kategorialnymi (nienumerycznymi)\n",
    "dataset_cat=dataset.select_dtypes(include='object')\n",
    "dataset_cat.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wydzielenie zmiennej zależnej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmienne wejściowe, cechy - zmienne **niezależne**\n",
    "\n",
    "Zmienna wyjściowa, wynik - zmienna **zależna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wydzielenie zmiennej zależnej (Y)\n",
    "x,y = dataset.drop(columns=[\"median value\"]), dataset[\"median value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis\n",
    "\n",
    "Eksploracyjna Analiza Danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podstawowa analiza statystyczna\n",
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramy zmiennych niezależnych\n",
    "x.hist(figsize=(15,10), bins=20, edgecolor='black', grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram zmiennej zależnej\n",
    "fig,axes = plt.subplots(figsize=(5,3))\n",
    "axes.hist(y*1000, bins=20, edgecolor='black')\n",
    "axes.set_xlabel('Median value of owner-occupied homes in $')\n",
    "axes.set_ylabel('Frequency')\n",
    "axes.set_title('Histogram of Median Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykresy BOXPLOT\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Zmienna zależna Y(median value) w zależności od ilości pokojów \n",
    "plt.clf()\n",
    "sns.boxplot(y=y, x=x[\"No. rooms\"].round())\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "sns.boxplot(y=x[\"No. rooms\"], x=y.round(-1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analiza korelacji pomiędzy zmiennymi\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(x.select_dtypes(exclude='object').corr(), ax=ax, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test, Val split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podział na trzy **niezależne** zestawy:\n",
    "* train - przygotowanie modelu\n",
    "* val - ocena i strojenie modelu\n",
    "* test - ostateczna ewaluacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podział na subsety TRAIN, TEST oraz VAL\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.4, random_state=42, shuffle=True)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skalowanie wartości niezależnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skalowanie zmiennych niezależnych numerycznych z użyciem StandardScaler\n",
    "# Enkodowanie zmiennych niezależnych kategorycznych z użyciem OrdinalEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder \n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "\n",
    "col_categorical = x_train.select_dtypes(include='object').columns # Kolumny kategoryczne\n",
    "col_numerical = x_train.select_dtypes(exclude='object').columns # Kolumny numeryczne\n",
    "\n",
    "# Transformer kolumn - pozwala skalować lub enkodować kolumny zależnie od ich rodzaju (numerical/categorical)\n",
    "col_transformer = make_column_transformer(\n",
    "    (StandardScaler(), col_numerical),\n",
    "    (OrdinalEncoder(), col_categorical)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresja - model regresji linowej, drzewo decyzyjne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresja liniowa\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Pipeline dla regresji liniowej\n",
    "linear_regressor = Pipeline([\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('linear_regressor', LinearRegression(positive=True))\n",
    "])\n",
    "linear_regressor.fit(x_train, y_train)\n",
    "\n",
    "y_pred = linear_regressor.predict(x_train)\n",
    "rmse_linear = mean_squared_error(y_train, y_pred)**.5\n",
    "r2_linear = r2_score(y_train, y_pred)\n",
    "print(f\"RMSE: {rmse_linear:.2f}\")\n",
    "print(f\"R^2: {r2_linear:.3f}\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "ax.plot(y_train, y_pred, '.')\n",
    "ax.plot([0, np.max(y_val)], [0, np.max(y_val)], color='red', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel(\"Oczekiwane wartości\")\n",
    "ax.set_ylabel(\"Predykcje\")\n",
    "ax.set_title(\"Zestaw treningowy\")\n",
    "ax.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drzewo decyzyjne\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Pipeline dla drzewa decyzyjnego\n",
    "decision_tree = Pipeline([\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('decision_tree', DecisionTreeRegressor())\n",
    "])\n",
    "decision_tree.fit(x_train, y_train)\n",
    "\n",
    "y_pred = decision_tree.predict(x_train)\n",
    "rmse_tree = mean_squared_error(y_train, y_pred)**.5\n",
    "r2_tree = r2_score(y_train, y_pred)\n",
    "print(f\"RMSE: {rmse_tree:.2f}\")\n",
    "print(f\"R^2: {r2_tree:.3f}\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "ax.plot(y_train, y_pred, '.')\n",
    "ax.plot([0, np.max(y_val)], [0, np.max(y_val)], color='red', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel(\"Oczekiwane wartości\")\n",
    "ax.set_ylabel(\"Predykcje\")\n",
    "ax.set_title(\"Zestaw treningowy\")\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Regresja liniowa vs Drzewo decyzyjne (test na zestawie treningowym)\")\n",
    "print(f\"RMSE: {rmse_linear:.2f} vs {rmse_tree:.2f} (niższa wartość lepsza)\")\n",
    "print(f\"R^2: {r2_linear:.3f} vs {r2_tree:.3f} (wyższa wartość lepsza)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ewaluacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ewaluacja regresji liniowej na zestawie walidacyjnym\n",
    "\n",
    "y_pred = linear_regressor.predict(x_val)\n",
    "rmse_linear = mean_squared_error(y_val, y_pred)**.5\n",
    "r2_linear = r2_score(y_val, y_pred)\n",
    "print(f\"RMSE: {rmse_linear:.2f}\")\n",
    "print(f\"R^2: {r2_linear:.3f}\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "ax.plot(y_val, y_pred, '.')\n",
    "ax.plot([0, np.max(y_val)], [0, np.max(y_val)], color='red', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel(\"Oczekiwane wartości\")\n",
    "ax.set_ylabel(\"Predykcje\")\n",
    "ax.set_title(\"Zestaw walidacyjny\")\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ewaluacja drzewa decyzyjnego na zestawie walidacyjnym\n",
    "\n",
    "y_pred = decision_tree.predict(x_val)\n",
    "rmse_tree = mean_squared_error(y_val, y_pred)**.5\n",
    "r2_tree = r2_score(y_val, y_pred)\n",
    "print(f\"RMSE: {rmse_tree:.2f}\")\n",
    "print(f\"R^2: {r2_tree:.3f}\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "ax.plot(y_val, y_pred, '.')\n",
    "ax.plot([0, np.max(y_val)], [0, np.max(y_val)], color='red', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel(\"Oczekiwane wartości\")\n",
    "ax.set_ylabel(\"Predykcje\")\n",
    "ax.set_title(\"Zestaw walidacyjny\")\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Regresja liniowa vs Drzewo decyzyjne (test na zestawie walidacyjnym)\")\n",
    "print(f\"RMSE: {rmse_linear:.2f} vs {rmse_tree:.2f} (niższa wartość lepsza)\")\n",
    "print(f\"R^2: {r2_linear:.3f} vs {r2_tree:.3f} (wyższa wartość lepsza)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strojenie hiperparametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listowanie parametrów drzewa decyzyjnego\n",
    "decision_tree['decision_tree'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dobór wielkości drzewa decyzyjnego\n",
    "rmse = []\n",
    "depths = [1, 2, 5, 10, 15, 20, 25, 50]\n",
    "for depth in depths:\n",
    "\n",
    "    decision_tree.set_params(**{'decision_tree__max_depth': depth})\n",
    "    decision_tree.fit(x_val, y_val)\n",
    "    y_pred = decision_tree.predict(x_val)\n",
    "    rmse.append(mean_squared_error(y_val, y_pred)**.5)\n",
    "\n",
    "best_depth, best_rmse = depths[np.argmin(rmse)], np.min(rmse)\n",
    "    \n",
    "\n",
    "print(f\"Best RMSE: {best_rmse:.2f} dla max_depth={best_depth}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zastosowanie hiperparametrów i ponowny trening\n",
    "decision_tree.set_params(**{'decision_tree__max_depth': best_depth})\n",
    "\n",
    "decision_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ewaluacja na zestawie walidacyjnym\n",
    "y_pred = decision_tree.predict(x_val)\n",
    "rmse_tree_tuned = mean_squared_error(y_val, y_pred)**.5\n",
    "r2_tree_tuned = r2_score(y_val, y_pred)\n",
    "print(f\"RMSE: {mean_squared_error(y_val, y_pred)**.5:.2f}\")\n",
    "print(f\"R^2: {r2_score(y_val, y_pred):.3f}\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "ax.plot(y_val, y_pred, '.')\n",
    "ax.plot([0, np.max(y_val)], [0, np.max(y_val)], color='red', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel(\"Oczekiwane wartości\")\n",
    "ax.set_ylabel(\"Predykcje\")\n",
    "ax.set_title(\"Zestaw walidacyjny\")\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Drzewo decyzyjne vs Drzewo decyzyjne ze strojonymi hiperparametrami (test na zestawie walidacyjnym)\")\n",
    "print(f\"RMSE: {rmse_tree:.2f} vs {rmse_tree_tuned:.2f} (niższa wartość lepsza)\")\n",
    "print(f\"R^2: {r2_tree:.3f} vs {r2_tree_tuned:.3f} (wyższa wartość lepsza)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selekcja cech metodą LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresja Lasso do oceny ważności zmiennych niezależnych\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Pipeline([\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('lasso', Lasso(alpha=1e-05, max_iter=4000))\n",
    "])\n",
    "\n",
    "lasso.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyznaczenie ważności zmiennych niezależnych i ich wizualizacja\n",
    "\n",
    "lasso_coef = np.abs(lasso['lasso'].coef_)\n",
    "lasso_coef /= np.sum(lasso_coef)\n",
    "\n",
    "THRESH = 0.045\n",
    "\n",
    "decision_tree_coef = np.abs(decision_tree['decision_tree'].feature_importances_)\n",
    "decision_tree_coef /= np.sum(decision_tree_coef)\n",
    "\n",
    "# plotting the Column Names and Importance of Columns. \n",
    "fig,axes = plt.subplots(1,2,figsize=(10,3))\n",
    "\n",
    "axes[0].bar(x_train.columns.values, lasso_coef)\n",
    "axes[0].axhline(y=THRESH, color='r', linestyle='-')\n",
    "axes[0].grid()\n",
    "axes[0].set_xticks(x_train.columns.values)\n",
    "axes[0].set_xticklabels(x_train.columns.values, rotation = 90)\n",
    "axes[0].set_title(\"Ważność cech wyznaczona metodą LASSO\")\n",
    "axes[0].set_xlabel(\"Nazwa cechy\")\n",
    "axes[0].set_ylabel(\"Wpływ\")\n",
    "\n",
    "axes[1].bar(x_train.columns.values, decision_tree_coef)\n",
    "axes[1].grid()\n",
    "axes[1].set_xticks(x_train.columns.values)\n",
    "axes[1].set_xticklabels(x_train.columns.values, rotation = 90)\n",
    "axes[1].set_title(\"Wpływ cech na model - Decision Tree\")\n",
    "axes[1].set_xlabel(\"Nazwa cechy\")\n",
    "axes[1].set_ylabel(\"Wpływ\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "features_selected = x_train.columns[lasso_coef > THRESH]\n",
    "features_ignored = x_train.columns[lasso_coef <= THRESH]\n",
    "print(features_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usunięcie zmiennych nieistotnych\n",
    "x_train = x_train.drop(columns=features_ignored)\n",
    "x_val = x_val.drop(columns=features_ignored)\n",
    "x_test = x_test.drop(columns=features_ignored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ponowne stworzenie pipeline'u oraz trenowanie modelu drzewa decyzyjnego dla zestawu z nowymi zmiennymi\n",
    "\n",
    "col_categorical = x_train.select_dtypes(include='object').columns\n",
    "col_numerical = x_train.select_dtypes(exclude='object').columns\n",
    "\n",
    "col_transformer = make_column_transformer(\n",
    "    (StandardScaler(), col_numerical),\n",
    "    (OrdinalEncoder(), col_categorical)\n",
    ")\n",
    "\n",
    "decision_tree = Pipeline([\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('decision_tree', DecisionTreeRegressor(max_depth=best_depth))\n",
    "])\n",
    "\n",
    "\n",
    "decision_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyznaczenie wpłwu cech niezależnych na model\n",
    "\n",
    "decision_tree_coef = np.abs(decision_tree['decision_tree'].feature_importances_)\n",
    "decision_tree_coef /= np.sum(decision_tree_coef)\n",
    "\n",
    "# plotting the Column Names and Importance of Columns. \n",
    "fig,ax = plt.subplots(1,1,figsize=(5,3))\n",
    "\n",
    "ax.bar(x_train.columns.values, decision_tree_coef)\n",
    "ax.grid()\n",
    "ax.set_xticks(x_train.columns.values)\n",
    "ax.set_xticklabels(x_train.columns.values, rotation = 90)\n",
    "ax.set_title(\"Wpływ cech na model - Decision Tree\")\n",
    "ax.set_xlabel(\"Nazwa cechy\")\n",
    "ax.set_ylabel(\"Wpływ\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ewaluacja na zestawie walidacyjnym\n",
    "y_pred = decision_tree.predict(x_val)\n",
    "rmse_tree_fewerftrs = mean_squared_error(y_val, y_pred)**.5\n",
    "r2_tree_fewerftrs = r2_score(y_val, y_pred)\n",
    "print(f\"RMSE: {rmse_tree_fewerftrs:.2f}\")\n",
    "print(f\"R^2: {r2_tree_fewerftrs:.3f}\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "ax.plot(y_val, y_pred, '.')\n",
    "ax.plot([0, np.max(y_val)], [0, np.max(y_val)], color='red', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel(\"Oczekiwane wartości\")\n",
    "ax.set_ylabel(\"Predykcje\")\n",
    "ax.set_title(\"Zestaw walidacyjny\")\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Drzewo decyzyjne vs Drzewo decyzyjne bez nieistotnych cech (test na zestawie walidacyjnym)\")\n",
    "print(f\"RMSE: {rmse_tree:.2f} vs {rmse_tree_fewerftrs:.2f} (niższa wartość lepsza)\")\n",
    "print(f\"R^2: {r2_tree:.3f} vs {r2_tree_fewerftrs:.3f} (wyższa wartość lepsza)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walidacja na zbiorze testowym (finalna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decision_tree.predict(x_test)\n",
    "print(f\"RMSE: {mean_squared_error(y_test, y_pred)**.5:.2f}\")\n",
    "print(f\"R^2: {r2_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "ax.plot(y_test, y_pred, '.')\n",
    "ax.plot([0, np.max(y_val)], [0, np.max(y_val)], color='red', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel(\"Oczekiwane wartości\")\n",
    "ax.set_ylabel(\"Predykcje\")\n",
    "ax.set_title(\"Zestaw testowy\") \n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak zmiana *SEED'a* pdoczas podziału na zestawy train/test/val wpływa na wyniki modelu?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
